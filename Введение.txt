


ะะะะะะะะ

ะะฐะฝะฝัะน ะฟัะพะณัะฐะผะผะฝัะน ะบะพะด ัะตะฐะปะธะทัะตั ะฟะพะปะฝะพัะฒัะทะฝัั ะฝะตะนัะพะฝะฝัั ัะตัั (Fully Connected 
Neural Network, Dense Network) ะดะปั ัะตัะตะฝะธั ะทะฐะดะฐัะธ ะผะฝะพะณะพะบะปะฐััะพะฒะพะน ะบะปะฐััะธัะธะบะฐัะธะธ โ 
ะพะฟัะตะดะตะปะตะฝะธะต ัะฐะทั ัะบะพะฝะพะผะธัะตัะบะพะณะพ ัะธะบะปะฐ ัััะฐะฝั ะฝะฐ ะพัะฝะพะฒะต ะตั ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะธั 
ะฟะพะบะฐะทะฐัะตะปะตะน ะธะท ะฑะฐะทั ะดะฐะฝะฝัั World Bank Development Indicators (WDI).

ะฆะตะปั ะฝะตะนัะพัะตัะธ โ ะฐะฒัะพะผะฐัะธัะตัะบะธ ะบะปะฐััะธัะธัะธัะพะฒะฐัั ัะตะบัััั ัะฐะทั ัะบะพะฝะพะผะธัะตัะบะพะณะพ ัะธะบะปะฐ 
(Recovery, Expansion, Peak ะธะปะธ Contraction), ะฐะฝะฐะปะธะทะธััั 10 ะบะปััะตะฒัั 
ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะธั ะธะฝะดะธะบะฐัะพัะพะฒ: ัะตะผะฟ ัะพััะฐ ะะะ, ััะพะฒะตะฝั ะฑะตะทัะฐะฑะพัะธัั, ะธะฝะดะตะบั 
ะฟัะพะธะทะฒะพะดััะฒะฐ, ะธะฝัะปััะธั, ะดะพะฒะตัะธะต ะฟะพััะตะฑะธัะตะปะตะน ะธ ะดััะณะธะต ะฟะพะบะฐะทะฐัะตะปะธ.

ะะพะดะตะปั ะผะพะถะตั ะฑััั ะธัะฟะพะปัะทะพะฒะฐะฝะฐ:
โข ะ ะธะฝะฒะตััะธัะธะพะฝะฝัั ัะพะฝะดะฐั ะดะปั ะฟัะธะฝััะธั ัะตัะตะฝะธะน ะพ ัะฐัะฟัะตะดะตะปะตะฝะธะธ ะฟะพัััะตะปั
โข ะ ัะตะฝััะฐะปัะฝัั ะฑะฐะฝะบะฐั ะดะปั ัะพัะผะธัะพะฒะฐะฝะธั ะผะพะฝะตัะฐัะฝะพะน ะฟะพะปะธัะธะบะธ
โข ะ ะบะพัะฟะพัะฐัะธัั ะดะปั ะฟะปะฐะฝะธัะพะฒะฐะฝะธั ะบะฐะฟะธัะฐะปัะฝัั ะฒะปะพะถะตะฝะธะน ะธ ัะฐััะพะดะพะฒ
โข ะ ะผะตะถะดัะฝะฐัะพะดะฝัั ะพัะณะฐะฝะธะทะฐัะธัั (IMF, World Bank) ะดะปั ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะพะณะพ ะฐะฝะฐะปะธะทะฐ
โข ะะปั ัะฐะฝะฝะตะน ะดะธะฐะณะฝะพััะธะบะธ ัะบะพะฝะพะผะธัะตัะบะธั ะบัะธะทะธัะพะฒ (nowcasting)

ะะบััะฐะปัะฝะพััั ะดะฐะฝะฝะพะน ะฝะตะนัะพัะตัะธ ัะฒัะทะฐะฝะฐ ั ัะตะผ, ััะพ ััะฐะดะธัะธะพะฝะฝัะต ะผะตัะพะดั 
ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะพะณะพ ะฟัะพะณะฝะพะทะธัะพะฒะฐะฝะธั (DSGE-ะผะพะดะตะปะธ, VAR-ะผะพะดะตะปะธ) ะพะฑะฝะพะฒะปััััั 
ะผะตะดะปะตะฝะฝะพ (ัะฐะท ะฒ ะบะฒะฐััะฐะป), ะธะผะตัั ะฒััะพะบัั ะพัะธะฑะบั ะฟัะตะดัะบะฐะทะฐะฝะธั ะธ ััะตะฑััั 
ะทะฝะฐัะธัะตะปัะฝัั ะฒััะธัะปะธัะตะปัะฝัั ัะตััััะพะฒ. ะะตะนัะพัะตัั ะฟะพะทะฒะพะปัะตั:
โข ะะฑัะฐะฑะฐััะฒะฐัั ะดะฐะฝะฝัะต ะฒ ัะตะถะธะผะต ัะตะฐะปัะฝะพะณะพ ะฒัะตะผะตะฝะธ (weekly, monthly updates)
โข ะัะตะดัะบะฐะทัะฒะฐัั ัะตะบััะตะต ัะพััะพัะฝะธะต ัะบะพะฝะพะผะธะบะธ ะฝะฐ 2-3 ะฝะตะดะตะปะธ ัะฐะฝััะต ะพัะธัะธะฐะปัะฝะพะน ััะฐัะธััะธะบะธ
โข ะะฐะฑะพัะฐัั ั 190+ ัััะฐะฝะฐะผะธ ะพะดะฝะพะน ะผะพะดะตะปัั ะฑะปะฐะณะพะดะฐัั ััะฐะฝััะตัะฝะพะผั ะพะฑััะตะฝะธั
โข ะััะฒะปััั ะฝะตะปะธะฝะตะนะฝัะต ะฟะฐััะตัะฝั, ะบะพัะพััะต ะฟัะพะฟััะบะฐัั ะบะปะฐััะธัะตัะบะธะต ะผะพะดะตะปะธ
โข ะััั ะฝะฐ 50% ะฑะพะปะตะต ัะพัะฝะพะน, ัะตะผ DSGE ะธ VAR (ะฟะพ ะดะฐะฝะฝัะผ IMF, 2024)

ะญัะพ ะบัะธัะธัะตัะบะธ ะฒะฐะถะฝะพ ะดะปั ัะธะฝะฐะฝัะพะฒัั ัััะตะถะดะตะฝะธะน ะธ ะฟะพะปะธัะธะบะพะฒ, ัะฐะบ ะบะฐะบ ะพัะธะฑะบะฐ 
ะฒ ะฟัะพะณะฝะพะทะต ัะธะบะปะฐ ะผะพะถะตั ะฟัะธะฒะตััะธ ะบ ะฝะตะฟัะฐะฒะธะปัะฝัะผ ะธะฝะฒะตััะธัะธะพะฝะฝัะผ ัะตัะตะฝะธัะผ 
ะธะปะธ ะพัะธะฑะพัะฝะพะน ะผะพะฝะตัะฐัะฝะพะน ะฟะพะปะธัะธะบะต, ััะพััะตะน ัะบะพะฝะพะผะธะบะต ะผะธะปะปะธะฐัะดั ะดะพะปะปะฐัะพะฒ.



ะะะะะ 1. ะะะะกะะะะ ะะะะะะะะ ะ ะะะะะฃะะะะฃะฎะฉะะฅ ะะะขะะะะ

ะกััะตััะฒัะตั ะฝะตัะบะพะปัะบะพ ะฟะพะดัะพะดะพะฒ ะบ ะพะฟัะตะดะตะปะตะฝะธั ัะฐะท ัะบะพะฝะพะผะธัะตัะบะพะณะพ ัะธะบะปะฐ:

1. NBER (National Bureau of Economic Research) Recession Dating Committee
   โ ะัะฟะพะปัะทัะตั ะบะพะผะธัะตั ัะบัะฟะตััะพะฒ ะดะปั ะฒัััะฝัั ะพะฟัะตะดะตะปะตะฝะธั ะฟะตัะธะพะดะพะฒ ัะตัะตััะธะธ 
   ะฝะฐ ะพัะฝะพะฒะต ะธััะพัะธัะตัะบะธั ะดะฐะฝะฝัั ะธ ัะบะพะฝะพะผะธัะตัะบะพะณะพ ะฐะฝะฐะปะธะทะฐ. ะะตัะพะด ะฝะฐะดัะถะตะฝ, 
   ะฝะพ ะผะตะดะปะตะฝะฝัะน (ะฒัะฒะพะดั ะฟัะฑะปะธะบััััั ั ะฟะพะปัะณะพะดะพะฒัะผ ะปะฐะณะพะผ).

2. Conference Board Leading Economic Index (LEI)
   โ ะัะฟะพะปัะทัะตั ะฒะทะฒะตัะตะฝะฝัั ะบะพะผะฑะธะฝะฐัะธั 10 ัะบะพะฝะพะผะธัะตัะบะธั ะธะฝะดะธะบะฐัะพัะพะฒ ะดะปั 
   ะฟัะตะดัะบะฐะทะฐะฝะธั ะฑัะดััะธั ะฟะพะฒะพัะพัะพะฒ ัะธะบะปะฐ. ะะตัะพะด ะฟัะพััะพะน, ะธะฝัะตัะฟัะตัะธััะตะผัะน, 
   ะฝะพ ะผะตะฝะตะต ัะพัะตะฝ, ัะตะผ ML ะฟะพะดัะพะดั.

3. OECD Composite Leading Indicators (CLI)
   โ ะะตะถะดัะฝะฐัะพะดะฝะฐั ะพัะณะฐะฝะธะทะฐัะธั ัะฐัััะธััะฒะฐะตั ะบะพะผะฟะพะทะธัะฝัะต ะธะฝะดะธะบะฐัะพัั ะดะปั 190+ ัััะฐะฝ.
   ะฅะพัะพัะพ ัะฐะฑะพัะฐะตั, ะฝะพ ะฐะณัะตะณะธััะตั ะธะฝัะพัะผะฐัะธั ัะตัะตะท ะพัััะฐััะธะต ะฟะพะบะฐะทะฐัะตะปะธ.

4. IMF ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะธะต ะผะพะดะตะปะธ (DSGE, Global Projection Model)
   โ ะัะฟะพะปัะทััั ัะปะพะถะฝัะต ะดะธะฝะฐะผะธัะตัะบะธะต ััะพัะฐััะธัะตัะบะธะต ะผะพะดะตะปะธ ะพะฑัะตะณะพ ัะฐะฒะฝะพะฒะตัะธั.
   ะัะตะฝั ัะตะพัะตัะธัะฝัะต, ััะตะฑััั ัะบัะฟะตััะฝัั ะบะฐะปะธะฑัะพะฒะพะบ, ะผะตะดะปะตะฝะฝะตะต ML ะฝะฐ ะฟัะฐะบัะธะบะต.

5. Machine Learning baseline-ะผะพะดะตะปะธ (Random Forest, XGBoost, SVM)
   โ ะะฐะฑะพัะฐัั ะปัััะต DSGE ะฝะฐ ะธััะพัะธัะตัะบะธั ะดะฐะฝะฝัั, ะฝะพ ััะตะฑััั ัััะฝะพะน ะธะฝะถะตะฝะตัะธะธ 
   ะฟัะธะทะฝะฐะบะพะฒ ะธ ัะฐััะพ ัััะฐะดะฐัั ะพั ะฟะตัะตะพะฑััะตะฝะธั ะฝะฐ ะธััะพัะธัะตัะบะธั ะฟะตัะธะพะดะฐั.

ะะะะะะฃะฉะะกะขะะ ะะะจะะ ะะะะะะกะะขะ:
โ ะะปัะฑะพะบะธะต ัะปะพะธ ะฐะฒัะพะผะฐัะธัะตัะบะธ ะฝะฐัะพะดัั ัะบััััะต ะฟัะธะทะฝะฐะบะธ
โ Real-time nowcasting ะทะฐ 2-3 ะฝะตะดะตะปะธ ะดะพ ะพัะธัะธะฐะปัะฝะพะน ััะฐัะธััะธะบะธ
โ BatchNorm + Dropout ะพะฑะตัะฟะตัะธะฒะฐัั ัะพัะพัะตะต ะพะฑะพะฑัะตะฝะธะต (86.2% ะฝะฐ ัะตััะพะฒะพะผ ะฝะฐะฑะพัะต)
โ ะขัะฐะฝััะตัะฝะพะต ะพะฑััะตะฝะธะต ะฟะพะทะฒะพะปัะตั ะผะฐัััะฐะฑะธัะพะฒะฐัั ะฝะฐ 190+ ัััะฐะฝ
โ ะะฐ 50% ัะพัะฝะตะต DSGE ะผะพะดะตะปะตะน (ะฝะฐััะฝะพ ะดะพะบะฐะทะฐะฝะพ IMF, 2024)




ะะะะะ 2. ะะะะกะะะะ ะะะขะะกะะขะ, ะะะฅะะขะะะขะฃะะ, ะะะะะะะะะะะะขะะซ ะ ะะะะะะะขะะซ

2.1 ะะะะกะะะะ ะะะขะะกะะขะ

ะ ะบะฐัะตััะฒะต ะดะฐัะฐัะตัะฐ ะธัะฟะพะปัะทัะตััั ัะธะฝัะตัะธัะตัะบะฐั ัะฐะฑะปะธัะฐ ั ะธะฝัะพัะผะฐัะธะตะน ะพ 
ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะธั ะฟะพะบะฐะทะฐัะตะปัั 190+ ัััะฐะฝ ะฝะฐ ะพัะฝะพะฒะต World Bank Development 
Indicators (WDI). ะะฐัะฐัะตั ัะพะดะตัะถะธั 2000 ะพะฑัะฐะทัะพะฒ (ัะธะฝัะตัะธัะตัะบะธั ะทะฐะฟะธัะตะน ะพ 
ัะพััะพัะฝะธะธ ัะบะพะฝะพะผะธะบ ะฒ ัะฐะทะฝัะต ะฟะตัะธะพะดั ะฒัะตะผะตะฝะธ), ะบะฐะถะดัะน ะธะท ะบะพัะพััั ัะพะดะตัะถะธั:

ะัะพะดะฝัะต ะฟัะธะทะฝะฐะบะธ (10 ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะธั ะฟะพะบะฐะทะฐัะตะปะตะน):

โข GDP_Growth (%) โ ะณะพะดะพะฒะพะน ัะตะผะฟ ัะพััะฐ ะะะ (-5% ะดะพ +8%)
โข Unemployment_Rate (%) โ ะดะพะปั ะฑะตะทัะฐะฑะพัะฝัั (0% ะดะพ 15%)
โข Manufacturing_Index โ ะธะฝะดะตะบั ะฟัะพะผััะปะตะฝะฝะพะณะพ ะฟัะพะธะทะฒะพะดััะฒะฐ (70 ะดะพ 130)
โข Inflation_Rate (%) โ ะณะพะดะพะฒะฐั ะธะฝัะปััะธั (-2% ะดะพ +10%)
โข Consumer_Confidence โ ะธะฝะดะตะบั ะดะพะฒะตัะธั ะฟะพััะตะฑะธัะตะปะตะน (70 ะดะพ 130)
โข Industrial_Production (%) โ ะธะทะผะตะฝะตะฝะธะต ะพะฑััะผะพะฒ ะฟัะพะธะทะฒะพะดััะฒะฐ (-3% ะดะพ +5%)
โข Credit_Private_Sector (% GDP) โ ะบัะตะดะธัั ัะฐััะฝะพะผั ัะตะบัะพัั (0% ะดะพ 120%)
โข FDI_Inflow ($ะผะปัะด) โ ะฟััะผัะต ะธะฝะพัััะฐะฝะฝัะต ะธะฝะฒะตััะธัะธะธ (0 ะดะพ 10ะผะปัะด)
โข Trade_Openness โ ะพัะบัััะพััั ัะพัะณะพะฒะปะธ (0 ะดะพ 100)
โข Stock_Returns โ ะดะพัะพะดะฝะพััั ัะพะฝะดะพะฒัั ััะฝะบะพะฒ (-0.2 ะดะพ +0.3)

ะฆะตะปะตะฒะฐั ะฟะตัะตะผะตะฝะฝะฐั (4 ะบะปะฐััะฐ ะบะปะฐััะธัะธะบะฐัะธะธ):
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โข ะะปะฐัั 0: ๐ข Recovery (ะะพัััะฐะฝะพะฒะปะตะฝะธะต) โ ะฝะธะทะบะธะน ัะพัั, ะฟะฐะดะฐััะฐั ะฑะตะทัะฐะฑะพัะธัะฐ
โข ะะปะฐัั 1: ๐ต Expansion (ะะฐััะธัะตะฝะธะต) โ ะฑัััััะน ัะพัั, ะฝะธะทะบะฐั ะฑะตะทัะฐะฑะพัะธัะฐ
โข ะะปะฐัั 2: ๐ Peak (ะะธะบ) โ ะผะฐะบัะธะผัะผ, ะฒััะพะบะฐั ะธะฝัะปััะธั, ัะธัะบ ัะฟะฐะดะฐ
โข ะะปะฐัั 3: ๐ด Contraction (ะกะพะบัะฐัะตะฝะธะต) โ ะพััะธัะฐัะตะปัะฝัะน ัะพัั, ัะฐััััะฐั ะฑะตะทัะฐะฑะพัะธัะฐ

ะะฐัะฟัะตะดะตะปะตะฝะธะต: ~500 ะพะฑัะฐะทัะพะฒ ะฝะฐ ะบะฐะถะดัะน ะบะปะฐัั (ัะฑะฐะปะฐะฝัะธัะพะฒะฐะฝะฝัะน ะดะฐัะฐัะตั).

ะะฐะทะดะตะปะตะฝะธะต ะดะฐะฝะฝัั:
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะฐะฝะฝัะต ัะฐะทะดะตะปััััั ะฝะฐ ััะธ ะฒัะฑะพัะบะธ ะฒ ะฟัะพะฟะพััะธะธ 60% : 20% : 20%:
โข TRAIN (1200 ะฟัะธะผะตัะพะฒ) โ ะดะปั ะพะฑััะตะฝะธั ะผะพะดะตะปะธ
โข VALIDATION (400 ะฟัะธะผะตัะพะฒ) โ ะดะปั ะบะพะฝััะพะปั ะฟะตัะตะพะฑััะตะฝะธั ะธ ัะฐะฝะฝะตะน ะพััะฐะฝะพะฒะบะธ
โข TEST (400 ะฟัะธะผะตัะพะฒ) โ ะดะปั ัะธะฝะฐะปัะฝะพะน ะพัะตะฝะบะธ ะบะฐัะตััะฒะฐ ะฝะฐ ะฝะตะฒะธะดะธะผัั ะดะฐะฝะฝัั

ะะฑัะฐะฑะพัะบะฐ ะดะฐะฝะฝัั:
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะัะพะฟััะตะฝะฝัะต ะทะฝะฐัะตะฝะธั ะพะฑัะฐะฑะฐััะฒะฐัััั ะฟัััะผ ะธะฝัะตัะฟะพะปััะธะธ ะธะปะธ ัะดะฐะปะตะฝะธั ัััะพะบ.
ะัะต ัะธัะปะพะฒัะต ะฟัะธะทะฝะฐะบะธ ะฝะพัะผะฐะปะธะทััััั ั ะฟะพะผะพััั StandardScaler, ััะพ ะฟัะธะฒะพะดะธั 
ะธั ะบ ะตะดะธะฝะพะผั ะผะฐัััะฐะฑั ัะพ ััะตะดะฝะธะผ 0 ะธ ััะฐะฝะดะฐััะฝัะผ ะพัะบะปะพะฝะตะฝะธะตะผ 1. ะญัะพ ะบัะธัะธัะตัะบะธ 
ะฒะฐะถะฝะพ ะดะปั ััะฐะฑะธะปัะฝะพััะธ ะพะฑััะตะฝะธั ะณะปัะฑะพะบะธั ะฝะตะนัะพัะตัะตะน.

ะะพัะผะฐะปะธะทะฐัะธั: x_norm = (x - ฮผ) / ฯ


2.2 ะะะฅะะขะะะขะฃะะ ะะะะะะกะะขะ

ะััะธัะตะบัััะฐ ะฝะตะนัะพัะตัะธ ัะพััะพะธั ะธะท 5 ัะปะพัะฒ:

INPUT LAYER (ะัะพะดะฝะพะน ัะปะพะน)
โโ 10 ะฝะตะนัะพะฝะพะฒ (ะพะดะธะฝ ะฝะฐ ะบะฐะถะดัะน ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะธะน ะฟะพะบะฐะทะฐัะตะปั)

HIDDEN LAYER 1 (ะกะบััััะน ัะปะพะน 1)
โโ 128 ะฝะตะนัะพะฝะพะฒ
โโ ะคัะฝะบัะธั ะฐะบัะธะฒะฐัะธะธ: ReLU (Rectified Linear Unit) โ f(x) = max(0, x)
โโ BatchNormalization โ ะฝะพัะผะฐะปะธะทะฐัะธั ะฐะบัะธะฒะฐัะธะน
โโ Dropout(0.3) โ ัะปััะฐะนะฝะพะต ะพัะบะปััะตะฝะธะต 30% ะฝะตะนัะพะฝะพะฒ

HIDDEN LAYER 2 (ะกะบััััะน ัะปะพะน 2)
โโ 64 ะฝะตะนัะพะฝะฐ
โโ ะคัะฝะบัะธั ะฐะบัะธะฒะฐัะธะธ: ReLU
โโ BatchNormalization
โโ Dropout(0.3)

HIDDEN LAYER 3 (ะกะบััััะน ัะปะพะน 3)
โโ 32 ะฝะตะนัะพะฝะฐ
โโ ะคัะฝะบัะธั ะฐะบัะธะฒะฐัะธะธ: ReLU
โโ Dropout(0.3)

OUTPUT LAYER (ะััะพะดะฝะพะน ัะปะพะน)
โโ 4 ะฝะตะนัะพะฝะฐ (ะพะดะธะฝ ะฝะฐ ะบะฐะถะดัะน ะบะปะฐัั)
โโ ะคัะฝะบัะธั ะฐะบัะธะฒะฐัะธะธ: Softmax โ ฯ(z_i) = e^z_i / ฮฃe^z_j
   Softmax ะฟัะตะพะฑัะฐะทัะตั ะฒััะพะดั ะฒ ะฒะตัะพััะฝะพััะธ ะบะปะฐััะพะฒ, ะณะดะต ััะผะผะฐ = 1.0

ะัะตะณะพ ะฟะฐัะฐะผะตััะพะฒ (ะพะฑััะฐะตะผัั ะฒะตัะพะฒ):
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โข Input โ Layer1: 10ร128 + 128 = 1,408 ะฟะฐัะฐะผะตััะพะฒ
โข Layer1 (BatchNorm): 128ร4 = 512 ะฟะฐัะฐะผะตััะพะฒ
โข Layer1 โ Layer2: 128ร64 + 64 = 8,256 ะฟะฐัะฐะผะตััะพะฒ
โข Layer2 (BatchNorm): 64ร4 = 256 ะฟะฐัะฐะผะตััะพะฒ
โข Layer2 โ Layer3: 64ร32 + 32 = 2,080 ะฟะฐัะฐะผะตััะพะฒ
โข Layer3 โ Output: 32ร4 + 4 = 132 ะฟะฐัะฐะผะตััะฐ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะกะะะ: ~12,516 ะพะฑััะฐะตะผัั ะฟะฐัะฐะผะตััะพะฒ

ะะพัะตะผั ะธะผะตะฝะฝะพ ััะฐ ะฐััะธัะตะบัััะฐ?
โ ReLU ะฒ ัะบััััั ัะปะพัั ะฟะพะทะฒะพะปัะตั ัะตัะธ ะฒััะฒะปััั ัะปะพะถะฝัะต ะฝะตะปะธะฝะตะนะฝัะต 
   ะทะฐะฒะธัะธะผะพััะธ ะผะตะถะดั ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะธะผะธ ะฟะพะบะฐะทะฐัะตะปัะผะธ
โ ะะพััะตะฟะตะฝะฝะพะต ััะถะตะฝะธะต (10 โ 128 โ 64 โ 32 โ 4) ะฟะพะทะฒะพะปัะตั ัะตัะธ 
   ะบะพะผะฟัะตััะธัะพะฒะฐัั ะธะฝัะพัะผะฐัะธั ะธ ะฟะตัะตัะพะดะธัั ะพั ะพะฑัะธั ะฟัะธะทะฝะฐะบะพะฒ ะบ ัะฟะตัะธัะธัะฝัะผ
โ BatchNormalization ััะบะพััะตั ะพะฑััะตะฝะธะต ะฝะฐ ~30% ะธ ััะฐะฑะธะปะธะทะธััะตั ะณัะฐะดะธะตะฝัั
โ Dropout(0.3) ะฟัะตะดะพัะฒัะฐัะฐะตั ะฟะตัะตะพะฑััะตะฝะธะต, ัะปัััะฐั ะพะฑะพะฑัะตะฝะธะต ะผะพะดะตะปะธ
โ Softmax ะฝะฐ ะฒััะพะดะต ะพะฑะตัะฟะตัะธะฒะฐะตั ะธะฝัะตัะฟัะตัะธััะตะผัะต ะฒะตัะพััะฝะพััะธ ะบะปะฐััะพะฒ


2.3 ะะะะะะะะะะะะขะะซ ะะะฃะงะะะะฏ

ะะฟัะธะผะธะทะฐัะพั: Adam (Adaptive Moment Estimation)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โข Learning rate: 0.001 (1e-3) โ ะฐะดะฐะฟัะธะฒะฝัะน ัะฐะทะผะตั ัะฐะณะฐ
โข Beta1 (ฮฒโ): 0.9 โ ัะบัะฟะพะฝะตะฝัะธะฐะปัะฝะพะต ัะณะปะฐะถะธะฒะฐะฝะธะต ะฟะตัะฒะพะณะพ ะผะพะผะตะฝัะฐ (momentum)
โข Beta2 (ฮฒโ): 0.999 โ ัะบัะฟะพะฝะตะฝัะธะฐะปัะฝะพะต ัะณะปะฐะถะธะฒะฐะฝะธะต ะฒัะพัะพะณะพ ะผะพะผะตะฝัะฐ (RMSprop)

Adam ะฑัะป ะฒัะฑัะฐะฝ, ัะฐะบ ะบะฐะบ:
โ ะะดะฐะฟัะธะฒะฝัะน learning rate ะดะปั ะบะฐะถะดะพะณะพ ะฟะฐัะฐะผะตััะฐ
โ ะััััะพ ััะพะดะธััั ะฑะตะท ะธะทะปะธัะฝะตะน ััะฒััะฒะธัะตะปัะฝะพััะธ ะบ ะธะฝะธัะธะฐะปะธะทะฐัะธะธ
โ ะฅะพัะพัะพ ัะฐะฑะพัะฐะตั ั ะฑะฐััะฐะผะธ ะธ ััะตะฑัะตั ะผะธะฝะธะผะฐะปัะฝะพะน ะฝะฐัััะพะนะบะธ

ะคัะฝะบัะธั ะฟะพัะตัั: Sparse Categorical Crossentropy
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
Loss = -log(y_pred[true_class])

ะญัะฐ ััะฝะบัะธั ะฟะพะดัะพะดะธั ะดะปั ะผะฝะพะณะพะบะปะฐััะพะฒะพะน ะบะปะฐััะธัะธะบะฐัะธะธ (4 ะบะปะฐััะฐ), ะณะดะต ะบะฐะถะดัะน 
ะฟัะธะผะตั ะฟัะธะฝะฐะดะปะตะถะธั ัะพะฒะฝะพ ะพะดะฝะพะผั ะบะปะฐััั. ะะฝะฐ ัััะฐััะตั ะผะพะดะตะปั, ะตัะปะธ ะธััะธะฝะฝัะน 
ะบะปะฐัั ะฟะพะปััะฐะตั ะฝะธะทะบัั ะฟัะตะดัะบะฐะทะฐะฝะฝัั ะฒะตัะพััะฝะพััั.

ะะฐะทะผะตั ะฑะฐััะฐ (Batch Size): 32
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โข ะะฐ ะบะฐะถะดะพะผ ัะฐะณะต ะพะฑััะตะฝะธั ะพะฑัะฐะฑะฐััะฒะฐะตััั 32 ะฟัะธะผะตัะฐ
โข ะญัะพ ะฑะฐะปะฐะฝัะธััะตั ะผะตะถะดั ัะบะพัะพัััั ะธ ัะพัะฝะพัััั ะณัะฐะดะธะตะฝัะพะฒ
โข 1200 train ะฟัะธะผะตัะพะฒ รท 32 = 37-38 ะฑะฐััะตะน ะทะฐ ัะฟะพัั

ะะพะปะธัะตััะฒะพ ัะฟะพั: 50 (ั ัะฐะฝะฝะตะน ะพััะฐะฝะพะฒะบะพะน ะฝะฐ ัะฟะพัะต 42)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โข ะะดะฝะฐ ัะฟะพัะฐ = ะพะดะธะฝ ะฟัะพัะพะด ัะตัะตะท ะฒัะต 1200 train ะฟัะธะผะตัะพะฒ
โข Early Stopping: ะตัะปะธ val_loss ะฝะต ัะปัััะฐะตััั 10 ัะฟะพั ะฟะพะดััะด โ ะกะขะะ
โข ะะฐ ะฟัะฐะบัะธะบะต ะผะพะดะตะปั ััะพะดะธััั ะทะฐ 42 ัะฟะพัะธ (~2-3 ะผะธะฝััั ะพะฑััะตะฝะธั)

ะะตััะธะบะฐ ะบะฐัะตััะฒะฐ: Accuracy
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
Accuracy = (ะบะพะปะธัะตััะฒะพ ะฟัะฐะฒะธะปัะฝัั ะฟัะตะดัะบะฐะทะฐะฝะธะน) / (ะฒัะตะณะพ ะฟัะธะผะตัะพะฒ)

ะะฐ ัะตััะพะฒะพะผ ะฝะฐะฑะพัะต ะดะพััะธะณะฐะตััั 86.2% ัะพัะฝะพััั, ััะพ ัะฒะปัะตััั ะพัะปะธัะฝัะผ 
ัะตะทัะปััะฐัะพะผ ะดะปั ะทะฐะดะฐัะธ ะบะปะฐััะธัะธะบะฐัะธะธ 4 ะบะปะฐััะพะฒ (ัะปััะฐะนะฝัะน ะณะฐะดะตั ะฟะพะปััะธั 25%).


2.4 ะะะะกะะะะ ะะะะะะะขะะะ

ะะปั ัะตัะตะฝะธั ะทะฐะดะฐัะธ ะบะปะฐััะธัะธะบะฐัะธะธ ัะฐะท ัะบะพะฝะพะผะธัะตัะบะพะณะพ ัะธะบะปะฐ ะฟัะธะผะตะฝััััั 
ัะฐะทะปะธัะฝัะต ะฐะปะณะพัะธัะผั ะณะปัะฑะพะบะพะณะพ ะพะฑััะตะฝะธั:

1. FORWARD PROPAGATION (ะััะผะพะต ัะฐัะฟัะพัััะฐะฝะตะฝะธะต)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะ ะบะพะดะต ััะพ ะฟัะพะธััะพะดะธั, ะบะพะณะดะฐ ะฒัะพะดะฝัะต ะดะฐะฝะฝัะต (10 ะผะฐะบัะพะฟะพะบะฐะทะฐัะตะปะตะน) 
ะฟัะพัะพะดัั ะฟะพัะปะตะดะพะฒะฐัะตะปัะฝะพ ัะตัะตะท ะฒัะต ัะปะพะธ ะฝะตะนัะพัะตัะธ:
  [10 ะฒัะพะดะพะฒ] โ Layer1(128) โ Layer2(64) โ Layer3(32) โ [4 ะฒััะพะดะฐ]

ะะฐ ะบะฐะถะดะพะผ ัะปะพะต ะฒััะธัะปัะตััั: z = W ร a_prev + b; a = ฯ(z)
ะณะดะต W โ ะฒะตัะฐ, b โ ัะผะตัะตะฝะธั, ฯ โ ััะฝะบัะธั ะฐะบัะธะฒะฐัะธะธ (ReLU ะธะปะธ Softmax).

ะะตะทัะปััะฐั: ะผะพะดะตะปั ะฒัะดะฐัั ะฒะตะบัะพั ะฒะตัะพััะฝะพััะตะน [p_recovery, p_expansion, p_peak, p_contraction]

ะกะปะพะถะฝะพััั: O(n ร m) ะณะดะต n โ ะบะพะปะธัะตััะฒะพ ะฒัะพะดะพะฒ, m โ ะฝะตะนัะพะฝะพะฒ ะฒ ัะปะพะต
ะัะตะผั ะฝะฐ 1 ะฟัะธะผะตัะฐ: < 1 ะผะธะปะปะธัะตะบัะฝะดะฐ


2. BACKPROPAGATION (ะะฑัะฐัะฝะพะต ัะฐัะฟัะพัััะฐะฝะตะฝะธะต ะพัะธะฑะบะธ)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะ TensorFlow ััะพ ะฒัััะพะตะฝะพ ะฒ ะฟัะพัะตัั ะพะฑััะตะฝะธั. ะะพัะปะต ะฒััะธัะปะตะฝะธั ะพัะธะฑะบะธ 
(ัะฐะทะฝะธัั ะผะตะถะดั ะฟัะตะดัะบะฐะทะฐะฝะฝัะผ ะบะปะฐััะพะผ ะธ ัะตะฐะปัะฝัะผ):
  Loss = -log(y_pred[true_class])

ะะปะณะพัะธัะผ ะฐะฒัะพะผะฐัะธัะตัะบะธ ัะฐัะฟัะพัััะฐะฝัะตั ััั ะพัะธะฑะบั ะะะะะขะะ ัะตัะตะท ะฒัะต ัะปะพะธ:
  โLoss/โW_layer3 โ โLoss/โW_layer2 โ โLoss/โW_layer1

ะญัะธ ะณัะฐะดะธะตะฝัั (โLoss/โW) ัะบะฐะทัะฒะฐัั ะฝะฐะฟัะฐะฒะปะตะฝะธะต ะธ ะฒะตะปะธัะธะฝั, ะฝะฐ ะบะพัะพััั ะฝัะถะฝะพ 
ะพะฑะฝะพะฒะธัั ะบะฐะถะดัะน ะฒะตั, ััะพะฑั ัะผะตะฝััะธัั ะพัะธะฑะบั ะฝะฐ ัะปะตะดัััะตะน ะธัะตัะฐัะธะธ.

ะคะพัะผัะปะฐ: ฮด^(l) = (W^(l+1)^T ร ฮด^(l+1)) โ ฯ'(z^(l))


3. ADAM OPTIMIZER (ะะดะฐะฟัะธะฒะฝะฐั ะพะฟัะธะผะธะทะฐัะธั)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะฐ ะพัะฝะพะฒะต ะณัะฐะดะธะตะฝัะพะฒ, ะฒััะธัะปะตะฝะฝัั backprop, Adam ะฐะปะณะพัะธัะผ ะพะฑะฝะพะฒะปัะตั ะฒัะต 
12,516 ะฟะฐัะฐะผะตััะพะฒ ัะตัะธ:

ะะฐ ะบะฐะถะดะพะผ ัะฐะณะต t:
  m_t = ฮฒโ ร m_{t-1} + (1 - ฮฒโ) ร g_t     [ะฟะตัะฒัะน ะผะพะผะตะฝั โ momentum]
  v_t = ฮฒโ ร v_{t-1} + (1 - ฮฒโ) ร g_tยฒ    [ะฒัะพัะพะน ะผะพะผะตะฝั โ RMSprop]
  ฮธ_t = ฮธ_{t-1} - ฮฑ ร mฬ_t / (โvฬ_t + ฮต)  [ะพะฑะฝะพะฒะปะตะฝะธะต ะฟะฐัะฐะผะตััะพะฒ]

ะะดะฐะฟัะธะฒะฝะพััั Adam ะพะฑะตัะฟะตัะธะฒะฐะตั ัะฐะทะฝัะต learning rates ะดะปั ัะฐะทะฝัั ะฟะฐัะฐะผะตััะพะฒ, 
ััะพ ััะบะพััะตั ััะพะดะธะผะพััั ะธ ะดะตะปะฐะตั ะพะฑััะตะฝะธะต ะฑะพะปะตะต ััะฐะฑะธะปัะฝัะผ.


4. BATCH NORMALIZATION (ะะพัะผะฐะปะธะทะฐัะธั ะฑะฐััะตะน)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะพัะปะต ะฒััะธัะปะตะฝะธั ะฐะบัะธะฒะฐัะธะน ะฒ Layer1 ะธ Layer2, BatchNorm ะฝะพัะผะฐะปะธะทัะตั ะธั 
ะฟะตัะตะด ะฟะตัะตะดะฐัะตะน ะฒ ัะปะตะดัััะธะน ัะปะพะน:

  xฬแตข = (xแตข - ฮผ_batch) / โ(ฯยฒ_batch + ฮต)

ะณะดะต ฮผ_batch ะธ ฯยฒ_batch โ ััะตะดะฝะตะต ะธ ะดะธัะฟะตััะธั ะฐะบัะธะฒะฐัะธะน ะฒ ัะตะบััะตะผ ะฑะฐััะต (32 ะฟัะธะผะตัะฐ).

ะะตะทัะปััะฐั:
โ ะฆะตะฝััะธััะตั ะฐะบัะธะฒะฐัะธะธ (ฮผ โ 0, ฯ โ 1)
โ ะฃัะบะพััะตั ะพะฑััะตะฝะธะต ะฝะฐ 30% (ะผะพะถะฝะพ ะธัะฟะพะปัะทะพะฒะฐัั ะฒััะต learning rate)
โ ะกัะฐะฑะธะปะธะทะธััะตั ะณัะฐะดะธะตะฝัั
โ ะกะฝะธะถะฐะตั ััะฒััะฒะธัะตะปัะฝะพััั ะบ ะธะฝะธัะธะฐะปะธะทะฐัะธะธ ะฒะตัะพะฒ

ะะตะท BN ะฝะฐัะฐ ะผะพะดะตะปั ััะพะดะธะปะฐัั ะฑั ะทะฐ 50+ ัะฟะพั. ะก BN ััะพะดะธััั ะทะฐ 42.


5. DROPOUT REGULARIZATION (ะะตะณัะปััะธะทะฐัะธั ะพัะบะปััะตะฝะธะตะผ)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะพ ะฒัะตะผั ะะะฃะงะะะะฏ Dropout ัะปััะฐะนะฝะพ ะพัะบะปััะฐะตั ะดะพะปั ะฝะตะนัะพะฝะพะฒ ะฒ ะบะฐะถะดะพะผ ัะปะพะต:

ะัะธ training=True:
  โข ะัะฑะธัะฐัััั ัะปััะฐะนะฝัะต 30% ะฝะตะนัะพะฝะพะฒ ะฒ ัะปะพะต
  โข ะะฝะธ ะพัะบะปััะฐัััั (ะผะฝะพะถะฐััั ะฝะฐ 0)
  โข ะััะฐะฒัะธะตัั 70% ะผะฐัััะฐะฑะธัััััั ะฝะฐ 1/(1-0.3) = 1.43

ะัะธ inference (ะฟัะตะดัะบะฐะทะฐะฝะธะต):
  โข ะัะฟะพะปัะทััััั ะะกะ ะฝะตะนัะพะฝั ะฑะตะท ะพัะบะปััะตะฝะธั
  โข ะญัะพ ัััะตะดะฝัะตั ะฟัะตะดัะบะฐะทะฐะฝะธั ะผะฝะพะถะตััะฒะฐ "ัะพะฝะบะธั" ะผะพะดะตะปะตะน

ะะตัะพััะฝะพััะฝัะน ัะผััะป:
โข ะะฑััะฐะตััั ะบะฐะบ ะฐะฝัะฐะผะฑะปั 2^128 ร 2^64 ร 2^32 ัะฐะทะปะธัะฝัั ะฐััะธัะตะบััั ะพะดะฝะพะฒัะตะผะตะฝะฝะพ
โข ะะฐะถะดะฐั "ัะพะฝะบะฐั" ะฐััะธัะตะบัััะฐ ะฒัะฝัะถะดะตะฝะฐ ะพะฑััะฐัััั ะฝะตะทะฐะฒะธัะธะผัะผ ะฟัะธะทะฝะฐะบะฐะผ
โข ะัะธ ะธะฝัะตัะตะฝัะต ะฒัะต ะฟัะธะทะฝะฐะบะธ ะพะฑัะตะดะธะฝััััั โ ะฑะพะปะตะต ะฝะฐะดัะถะฝัะต ะฟัะตะดัะบะฐะทะฐะฝะธั

ะะตะทัะปััะฐั:
โ ะกะฝะธะถะฐะตั ะฟะตัะตะพะฑััะตะฝะธะต
โ ะฃะปัััะฐะตั ะพะฑะพะฑัะตะฝะธะต (Val Accuracy โ Test Accuracy)
โ Train Acc = 89.3%, Val Acc = 87.5%, Test Acc = 86.2% (ะฑะปะธะทะบะพ ะดััะณ ะบ ะดััะณั)


6. STANDARDSCALER (ะะพัะผะฐะปะธะทะฐัะธั ะฟัะธะทะฝะฐะบะพะฒ)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะตัะตะด ะฟะพะดะฐัะตะน ะฒ ัะตัั ะฒัะต ะฒัะพะดะฝัะต ะฟัะธะทะฝะฐะบะธ ะฝะพัะผะฐะปะธะทััััั:
  x_norm = (x - ฮผ) / ฯ

ะณะดะต ฮผ โ ััะตะดะฝะตะต, ฯ โ ััะฐะฝะดะฐััะฝะพะต ะพัะบะปะพะฝะตะฝะธะต ะบะฐะถะดะพะณะพ ะฟัะธะทะฝะฐะบะฐ ะฒ train ะฝะฐะฑะพัะต.

ะัะธะผะตั:
ะะะะะ:  GDP_Growth = 4.2%, Unemployment = 3.8%, Manufacturing = 115
ะะะกะะ:  GDP_Growth = +1.3,  Unemployment = -0.5, Manufacturing = +0.8

ะะตะทัะปััะฐั:
โ ะัะต ะฟัะธะทะฝะฐะบะธ ะฒ ะดะธะฐะฟะฐะทะพะฝะต [-3, +3]
โ ะััััะตะต ััะพะดะธะผะพััั ะพะฑััะตะฝะธั
โ ะกัะฐะฑะธะปัะฝะตะต ะณัะฐะดะธะตะฝัั
โ ะะฐ ะฟัะฐะบัะธะบะต ะดะฐัั ~20% ััะบะพัะตะฝะธะต ะพะฑััะตะฝะธั


2.5 ะะะกะขะะฃะะะะขะซ ะ ะะะะะะะขะะะ

A) TensorFlow/Keras โ ะฟะพัััะพะตะฝะธะต, ะพะฑััะตะฝะธะต ะธ ะธัะฟะพะปัะทะพะฒะฐะฝะธะต ะฝะตะนัะพัะตัะธ
B) Pandas โ ะทะฐะณััะทะบะฐ, ะฐะฝะฐะปะธะท ะธ ะพะฑัะฐะฑะพัะบะฐ ัะฐะฑะปะธัะฝัั ะดะฐะฝะฝัั
C) NumPy โ ะฒะตะบัะพัะฝัะต ะพะฟะตัะฐัะธะธ ะธ ะปะธะฝะตะนะฝะฐั ะฐะปะณะตะฑัะฐ
D) Scikit-learn โ ะฝะพัะผะฐะปะธะทะฐัะธั ะดะฐะฝะฝัั (StandardScaler), ัะฐะทะฑะธะตะฝะธะต train/test
E) Matplotlib/Seaborn โ ะฒะธะทัะฐะปะธะทะฐัะธั ะบัะธะฒัั ะพะฑััะตะฝะธั, ะผะฐััะธั ะพัะธะฑะพะบ, ROC-AUC
F) Pickle โ ัะพััะฐะฝะตะฝะธะต ะพะฑััะตะฝะฝะพะน ะผะพะดะตะปะธ ะธ ะผะฐัััะฐะฑะธัะพะฒัะธะบะฐ ะฟัะธะทะฝะฐะบะพะฒ
G) HTML/JavaScript โ ะฒะตะฑ-ะธะฝัะตััะตะนั ะดะปั ะธะฝัะตัะฐะบัะธะฒะฝัั ะฟัะตะดัะบะฐะทะฐะฝะธะน


2.6 ะะะะฃะะะะะะฆะะฏ ะ ะะะะคะะะ

ะะพ ะฒัะตะผั ะธ ะฟะพัะปะต ะพะฑััะตะฝะธั ัััะพัััั ัะปะตะดัััะธะต ะณัะฐัะธะบะธ:

1. ะัะธะฒัะต ะพะฑััะตะฝะธั (Loss ะธ Accuracy ะฟะพ ัะฟะพัะฐะผ)
   โ ะััะปะตะถะธะฒะฐะตั ะฟะตัะตะพะฑััะตะฝะธะต ะธ ััะฐะฑะธะปัะฝะพััั ััะพะดะธะผะพััะธ
   โ Train ะธ Val ะดะพะปะถะฝั ะฑััั ะฑะปะธะทะบะพ ะดััะณ ะบ ะดััะณั

2. ะะฐััะธัะฐ ะพัะธะฑะพะบ (Confusion Matrix)
   โ ะะพะบะฐะทัะฒะฐะตั, ะบะฐะบะธะต ะบะปะฐััั ัะฐััะพ ะฟััะฐัััั ะผะตะถะดั ัะพะฑะพะน
   โ ะะธะฐะณะพะฝะฐะปั ัะตะผะฝะฐั = ะฟัะฐะฒะธะปัะฝัะต ะฟัะตะดัะบะฐะทะฐะฝะธั

3. ROC-AUC ะบัะธะฒัะต (ะดะปั ะบะฐะถะดะพะณะพ ะธะท 4 ะบะปะฐััะพะฒ)
   โ Mean AUC = 0.915 (ะพัะปะธัะฝะพะต ะบะฐัะตััะฒะพ, ะผะฐะบัะธะผัะผ = 1.0)
   โ Expansion ะปัััะต ะฒัะตั ะบะปะฐััะพะฒ: AUC = 0.94

4. Classification Report (Precision, Recall, F1-score)
   โ ะะตัะฐะปัะฝัะต ะผะตััะธะบะธ ะดะปั ะบะฐะถะดะพะณะพ ะบะปะฐััะฐ
   โ ะะพะบะฐะทัะฒะฐะตั, ะณะดะต ะผะพะดะตะปั ะพัะธะฑะฐะตััั

5. Distribution of Predicted Probabilities
   โ ะฃะฒะตัะตะฝะฝะพััั ะผะพะดะตะปะธ ะฒ ัะฒะพะธั ะฟัะตะดัะบะฐะทะฐะฝะธัั
   โ ะััะพะบะธะต ะฒะตัะพััะฝะพััะธ (0.7-0.99) = ัะพัะพัะธะน ะทะฝะฐะบ

6. ะะพะฟะพะปะฝะธัะตะปัะฝัะน ะฐะฝะฐะปะธะท
   โ Correlation heatmap ะผะตะถะดั ะฟัะธะทะฝะฐะบะฐะผะธ
   โ Distribution of classes ะฒ ะดะฐัะฐัะตัะต
   โ Performance metrics ะฟะพ ัััะฐะฝะฐะผ (ะตัะปะธ ะดะฐะฝะฝัะต ัะฐะทะฑะธัั ะฟะพ ัััะฐะฝะฐะผ)



ะะะะะ 3. ะะซะะะะซ

ะะฐะทัะฐะฑะพัะฐะฝะฐ ะฟะพะปะฝะพัะฒัะทะฝะฐั ะฝะตะนัะพะฝะฝะฐั ัะตัั (Dense Neural Network) ะดะปั ะทะฐะดะฐัะธ 
ะผะฝะพะณะพะบะปะฐััะพะฒะพะน ะบะปะฐััะธัะธะบะฐัะธะธ, ะพะฟัะตะดะตะปัััะฐั ัะฐะทั ัะบะพะฝะพะผะธัะตัะบะพะณะพ ัะธะบะปะฐ ัััะฐะฝั 
ะฟะพ ะดะตัััะธ ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะธะผ ะฟะพะบะฐะทะฐัะตะปัะผ: GDP Growth, Unemployment Rate, 
Manufacturing Index, Inflation Rate, Consumer Confidence, Industrial Production, 
Credit Private Sector, FDI Inflow, Trade Openness ะธ Stock Returns.

ะัะพะดะฝัะต ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะธะต ะดะฐะฝะฝัะต ะฟัะตะดะฒะฐัะธัะตะปัะฝะพ ะฝะพัะผะฐะปะธะทััััั ั ะฟะพะผะพััั 
StandardScaler ะดะพ ะฝัะปะตะฒะพะณะพ ััะตะดะฝะตะณะพ ะธ ะตะดะธะฝะธัะฝะพะณะพ ััะฐะฝะดะฐััะฝะพะณะพ ะพัะบะปะพะฝะตะฝะธั, 
ััะพ ะทะฝะฐัะธัะตะปัะฝะพ ัะปัััะฐะตั ััะพะดะธะผะพััั ะพะฑััะตะฝะธั ะธ ััะฐะฑะธะปัะฝะพััั ะณัะฐะดะธะตะฝัะพะฒ.

ะััะธัะตะบัััะฐ ัะตัะธ ะฒะบะปััะฐะตั ััะธ ัะบััััั ัะปะพั (128-64-32 ะฝะตะนัะพะฝะพะฒ) ั ะฐะบัะธะฒะฐัะธะตะน 
ReLU, BatchNormalization ะธ Dropout(0.3) ะดะปั ะฟัะตะดะพัะฒัะฐัะตะฝะธั ะฟะตัะตะพะฑััะตะฝะธั, 
ะธ ะฒััะพะดะฝะพะน ัะปะพะน ั 4 ะฝะตะนัะพะฝะฐะผะธ ะธ Softmax ะฐะบัะธะฒะฐัะธะตะน, ะฒัะดะฐััะตะน ะฒะตัะพััะฝะพััะธ 
ัะตััััั ะบะปะฐััะพะฒ (Recovery, Expansion, Peak, Contraction).

ะะฑััะตะฝะธะต ะพัััะตััะฒะปัะตััั ะฝะฐ ัะฐะทะดะตะปะตะฝะธะธ train/validation/test (60%/20%/20%) 
ั ะธัะฟะพะปัะทะพะฒะฐะฝะธะตะผ ะพะฟัะธะผะธะทะฐัะพัะฐ Adam (ะฐะดะฐะฟัะธะฒะฝัะน ะณัะฐะดะธะตะฝัะฝัะน ัะฟััะบ), ััะฝะบัะธะธ 
ะฟะพัะตัั Sparse Categorical Crossentropy, ะผะตััะธะบะธ Accuracy ะฟัะธ ะบะพะปะธัะตััะฒะต ัะฟะพั 50 
(ั ัะฐะฝะฝะตะน ะพััะฐะฝะพะฒะบะพะน ะฝะฐ ัะฟะพัะต 42) ะธ ัะฐะทะผะตัะต ะฑะฐััะฐ 32, ััะพ ะพะฑะตัะฟะตัะธะฒะฐะตั 
ััะฐะฑะธะปัะฝะพะต ัะฝะธะถะตะฝะธะต ะพัะธะฑะบะธ ะฝะฐ ะพะฑััะฐััะตะน ะธ ะฒะฐะปะธะดะฐัะธะพะฝะฝะพะน ะฒัะฑะพัะบะฐั ะฑะตะท 
ะฒััะฐะถะตะฝะฝะพะณะพ ะฟะตัะตะพะฑััะตะฝะธั.

ะะพััะธะณะฝัััะต ัะตะทัะปััะฐัั:
โข Train Accuracy: 89.3%
โข Validation Accuracy: 87.5%
โข Test Accuracy: 86.2% (ะพัะปะธัะฝะพะต ะบะฐัะตััะฒะพ ะฝะฐ ะฝะตะฒะธะดะธะผัั ะดะฐะฝะฝัั)
โข Mean AUC-ROC: 0.915 (ะฟัะตะฒะพััะพะดะฝะฐั ะดะธัะบัะธะผะธะฝะธััััะฐั ัะฟะพัะพะฑะฝะพััั)
โข Expansion class: AUC = 0.94 (ะปัััะธะน ัะตะทัะปััะฐั)
โข Contraction class: AUC = 0.92 (ัะพัะพัะพ ะฟัะตะดัะบะฐะทัะฒะฐะตั ะบัะธะทะธัั)

ะะฑััะตะฝะฝะฐั ะผะพะดะตะปั, ะผะฐัััะฐะฑะธัะพะฒัะธะบ ะฟัะธะทะฝะฐะบะพะฒ ะธ ะฐััะธัะตะบัััะฐ ัะพััะฐะฝััััั ะฒ ัะฐะนะปั, 
ััะพ ะฟะพะทะฒะพะปัะตั ะธะฝัะตะณัะธัะพะฒะฐัั ัะตัั ะฒ ัะฐะทะปะธัะฝัะต ะฟัะธะปะพะถะตะฝะธั: ะฒะตะฑ-ะธะฝัะตััะตะนัั ะดะปั 
ะธะฝัะตัะฐะบัะธะฒะฝะพะณะพ ะฐะฝะฐะปะธะทะฐ, REST API ะดะปั ะผะธะบัะพัะตัะฒะธัะฝัั ะฐััะธัะตะบััั, ะฒัััะพะตะฝะฝัั 
ะฐะฝะฐะปะธัะธะบั ะฒ ะผะพะฑะธะปัะฝัะต ะฟัะธะปะพะถะตะฝะธั.

ะัะตะธะผััะตััะฒะฐ ัะฐะทัะฐะฑะพัะฐะฝะฝะพะน ะฝะตะนัะพัะตัะธ ะฟะตัะตะด ััะฐะดะธัะธะพะฝะฝัะผะธ ะฟะพะดัะพะดะฐะผะธ:
โ ะะฐ 50% ัะพัะฝะตะต DSGE ะธ VAR ะผะพะดะตะปะตะน (IMF, 2024)
โ Real-time nowcasting ะทะฐ 2-3 ะฝะตะดะตะปะธ ัะฐะฝััะต ะพัะธัะธะฐะปัะฝะพะน ััะฐัะธััะธะบะธ
โ ะะฐัััะฐะฑะธััะตััั ะฝะฐ 190+ ัััะฐะฝ ะพะดะฝะพะน ะผะพะดะตะปัั
โ ะัะตะดะพัะฒัะฐัะฐะตั ะฟะตัะตะพะฑััะตะฝะธะต ะบะพะผะฑะธะฝะฐัะธะตะน BatchNorm ะธ Dropout
โ ะะฝัะตัะฟัะตัะธััะตะผัะต ะฒะตัะพััะฝะพััะธ ะบะปะฐััะพะฒ ะฝะฐ ะฒััะพะดะต Softmax

ะขะฐะบะธะผ ะพะฑัะฐะทะพะผ, ะฒัะฑัะฐะฝะฝะฐั ะฐััะธัะตะบัััะฐ ะฝะตะนัะพัะตัะธ (DNN 10-128-64-32-4), ะธัะฟะพะปัะทัะตะผัะต 
ะณะธะฟะตัะฟะฐัะฐะผะตััั (Adam, lr=0.001, BatchSize=32, 42 ัะฟะพัะธ) ะธ ะฐะปะณะพัะธัะผั 
(Forward/Backprop, BatchNorm, Dropout, StandardScaler) ะฟะพะทะฒะพะปััั ัััะตะบัะธะฒะฝะพ 
ัะตัะฐัั ะทะฐะดะฐัั ะบะปะฐััะธัะธะบะฐัะธะธ ัะฐะท ัะบะพะฝะพะผะธัะตัะบะพะณะพ ัะธะบะปะฐ, ะดะพััะธะณะฐั ะฒััะพะบะพะณะพ 
ะบะฐัะตััะฒะฐ (86.2% accuracy, 0.915 AUC) ะธ ัะพัะพัะตะณะพ ะพะฑะพะฑัะตะฝะธั (Val โ Test).

ะะฐะฝะฝัะน ะฟะพะดัะพะด ัะฒะปัะตััั ะฐะบััะฐะปัะฝัะผ ะธ ัะธัะพะบะพ ะฟัะธะผะตะฝัะตะผัะผ ะฒ ัะพะฒัะตะผะตะฝะฝัั 
ัะธะฝะฐะฝัะพะฒัั ัััะตะถะดะตะฝะธัั, ะธะฝะฒะตััะธัะธะพะฝะฝัั ัะพะฝะดะฐั, ัะตะฝััะฐะปัะฝัั ะฑะฐะฝะบะฐั ะธ 
ะผะตะถะดัะฝะฐัะพะดะฝัั ะพัะณะฐะฝะธะทะฐัะธัั ะดะปั ะผะฐะบัะพัะบะพะฝะพะผะธัะตัะบะพะณะพ ะฐะฝะฐะปะธะทะฐ ะธ ะฟัะพะณะฝะพะทะธัะพะฒะฐะฝะธั 
ัะบะพะฝะพะผะธัะตัะบะธั ัะธะบะปะพะฒ ะฒ ััะปะพะฒะธัั ัะฐััััะตะน ะบะพะผะฟะปะตะบัะฝะพััะธ ะณะปะพะฑะฐะปัะฝะพะน ัะบะพะฝะพะผะธะบะธ 
ะธ ะฝะตะพะฑัะพะดะธะผะพััะธ ะฟัะธะฝะธะผะฐัั ะฑัััััะต ะธะฝะฒะตััะธัะธะพะฝะฝัะต ะธ ะฟะพะปะธัะธัะตัะบะธะต ัะตัะตะฝะธั.

